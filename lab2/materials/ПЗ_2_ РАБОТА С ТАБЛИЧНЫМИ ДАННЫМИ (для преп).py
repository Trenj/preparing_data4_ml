# -*- coding: utf-8 -*-
"""ПЗ_2: РАБОТА С ТАБЛИЧНЫМИ ДАННЫМИ (для преп).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LQTLjWWQPdF6NwFQWd8p1ciE_gNzS4i3

# Практическая работа 2: "Работа с табличными данными" (для препод-ля)

**Задание 1**. Подключение библиотек

<p>При выполнении практической работы будут использоваться следующие библиотеки:</p>
<table>
    <tr>
        <th>Библиотека</th>
        <th>Назначение</th>
    </tr>
    <tr>
        <td><a href="https://pandas.pydata.org/docs/">Pandas</a></td>
    </tr>
    <tr>
        <td><a href="https://numpy.org/doc/">Numpy</a></td>
    </tr>
    <tr>
        <td><a href="https://matplotlib.org/stable/index.html">Matplotlib</a></td>
    </tr>
    
</table>
Заполните колонку "Назначение" в таблице и ниже подключите библиотеки для работы.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""**Задание 2**. Интеграция данных

***Интеграция данных*** - это процесс объединения данных их нескольких источников в единый набор данных (датасет). Объединение можно выполнить как *вертикально* (обычное склеивание), так и *горизонтальное* (аналог *join*() по ключу).

Создайте **2 набора данных** и проведите их *вертикальное* склеивание, используя функцию *concat*().

Ответьте на следующие вопросы:
1. Как создать набор данных?
2. Какие параметры принимает функция *concat*()?
"""

# Создаем первый датафрейм 5x5
df1 = pd.DataFrame(
    np.random.randint(0, 100, size=(5, 5)),
    columns=[f'A{i}' for i in range(1, 6)]
)

# Создаем второй датафрейм 5x5 (те же столбцы!)
df2 = pd.DataFrame(
    np.random.randint(0, 100, size=(5, 5)),
    columns=[f'A{i}' for i in range(1, 6)]
)

# Вертикальное склеивание (axis=0)
df_concat = pd.concat([df1, df2], axis=0)

print("DataFrame 1:")
print(df1)

print("\nDataFrame 2:")
print(df2)

print("\nРезультат вертикального склеивания:")
print(df_concat)

"""Создайте **2 набора данных** и выполните *горизонтальное* склеивание, используя функцию merge().

Ответьте на следующие вопросы:
1. В чем разница между *concat*() и *merge*()?
2. Какие параметры принимает функция *merge*()?
3. Выполните *left*, *right*, *inner*, *outher* склеивание и сделайте выводы, относительно разницы полученных результатов.
"""

df1 = pd.DataFrame({
    'id': [1, 2, 3],
    'A': [10, 20, 30],
    'B': [100, 200, 300]
})

df2 = pd.DataFrame({
    'id': [2, 3, 4],
    'C': [400, 500, 600],
    'D': [40, 50, 60]
})

print("\nLEFT DATASET:")
print(df1)

print("\nRIGHT DATASET:")
print(df2)

# INNER_JOIN (по умолчанию)
inner_merge = pd.merge(df1, df2, on='id', how='inner')

# LEFT_JOIN
left_merge = pd.merge(df1, df2, on='id', how='left')

# RIGHT_JOIN
right_merge = pd.merge(df1, df2, on='id', how='right')

# OUTER_JOIN
outer_merge = pd.merge(df1, df2, on='id', how='outer')

print("\nINNER MERGE:")
print(inner_merge)

print("\nLEFT MERGE:")
print(left_merge)

print("\nRIGHT MERGE:")
print(right_merge)

print("\nOUTER MERGE:")
print(outer_merge)

"""**Задание 3**. Оценка объема данных


***Оценка объема данных*** необходима для определения сложности решаемой задачи и достаточности данных для ее решения. Оценка объема позволяет определить не только количество данных, но также и количество атрибутов.
1. Загрузите датасет *parkinson_disease.csv* из курса.
2. При помощи методов *shape*(), *size*() и *info*() изучите набор данных:    

*   какие атрибуты и какого типа представлены,
*   размер набора данных,
*   количество строк и колонок,
*   есть ли пропущенные строки и т.д.
3. Сделать выводы относительно качества исходных данных.
"""

data = pd.read_csv('parkinson_disease.csv')
data

print(data.size)
print(data.shape)
print(len(data.index))
print(len(data.columns))

data.info()

"""Размер 756 строк на 755 столбцов
749 столбцов с типом float, 6 с типом int 64
Используемая память 4,4 Мб

**Задание 4**. Преобразование и очистка данных

4.1. Определить количество ***уникальных*** значений в каждом столбце. Оценить возможность преобразования данных в числовые значения.
"""

data.nunique()

"""4.2. Получите информацию по ***атрибутам***: количество, средние значения, отклонения, квартили.

Сделать выводы по полученным данным.
"""

data.describe().T

"""4.3. Преобразуйте **категориальные** признаки, предварительно проверив возможность этого преобразования.

Проверьте данные на пустоту и проанализируйте можно ли преобразовать признаки в числовой формат, повторяются ли данные, дублируются ли они.
"""

data.isnull().sum()

print(data['id'])

"""4.4. Проверить набор данных на **дубликаты**

Можно заметить, что есть дублирование данных по ***id***. Можно склеить строки с одинаковым значением, расcчитав среднее по каждому из атрибутов.
"""

data = data.groupby('id').mean().reset_index()
data.drop('id', axis=1, inplace=True)
data

"""**Задание 5**. Матрица корреляции

5.1. Постройте матрицу корреляции для всех признаков и сделайте выводы.

5.2. Используя *corr*(), удалим ***сильнокоррелирующие*** признаки, корреляция которых превосходит 0,7. Определим, текущий размер датасета.

"""

exclude_cols = ['class']
cols_to_analyze = [col for col in data.columns if col not in exclude_cols]

if cols_to_analyze:
    # Вычисляем корреляционную матрицу
    corr_matrix = data[cols_to_analyze].corr().abs()

    # Находим признаки для удаления
    cols_to_drop = set()

    for i in range(len(corr_matrix.columns)):
        for j in range(i + 1, len(corr_matrix.columns)):
            if corr_matrix.iloc[i, j] > 0.7:
                col_j = corr_matrix.columns[j]
                if col_j not in cols_to_drop:
                    cols_to_drop.add(col_j)

    # Удаляем признаки
    cols_to_keep = [col for col in data.columns if col not in cols_to_drop]
    data = data[cols_to_keep]

print(data.shape)

"""5.3. *Уменьшим* количество признаков, используя методику хи-квадрат Пирсона, и оставим только те, которые оказывают наибольшее влияние.

Для этого необходимо:
1. Удалить результирующую колонку.
2. Нормализовать значения в диапазоне от 0 до 1.
3. Применить хи-квадрат для выбора $n$ и более признаков (в качестве учебной задачи можем взять **10** признаков).
4. Извлечь 10 признаков и соединить их с результирующей колонкой.
"""

from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.feature_selection import SelectKBest, chi2

original_index = data.index
X = data.drop('class', axis=1)
X_norm = MinMaxScaler().fit_transform(X)
selector = SelectKBest(chi2, k=10)
selector.fit(X_norm, data['class'])
selected_mask = selector.get_support()
selected_features = X.columns[selected_mask]

# Создаем новый DataFrame
new_data = pd.DataFrame(
    data=X_norm[:, selected_mask],
    columns=selected_features,
    index=original_index
)

# Добавляем целевую переменную
new_data['class'] = data['class'].values

data = new_data
data

"""5.4. Постройте ***матрицу корреляции*** для **10** признаков и сделайте выводы."""

corr = data.corr()
corr

"""(*) 5.5. Постройте ***тепловую матрицу корреляции*** и сделайте выводы."""

import seaborn as sns
co_mtx = data.corr(numeric_only=True)
sns.heatmap(co_mtx, cmap="YlGnBu", annot=True)

"""Напишите выводы на основе полученной корреляционной матрицы.

**Задание 6**. Визуализация данных

Описание шкалы измерения атрибутов, визуализация.
Реализуйте функцию для визуализации атрибутов `visualize_dataset_attributes()`.
"""

def visualize_dataset_attributes(data, target_col='class', figsize=(20, 15)):

    # Определяем типы признаков
    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()

    # Убираем целевую переменную из численных признаков для анализа
    if target_col in numeric_cols:
        numeric_cols.remove(target_col)

    # 1. Распределение числовых признаков
    if numeric_cols:
        n_numeric = len(numeric_cols)
        n_cols = 4  # Фиксируем 4 графика в ряду
        n_rows = int(np.ceil(n_numeric / n_cols))

        fig, axes = plt.subplots(n_rows, n_cols, figsize=(figsize[0], n_rows * 5))
        axes = axes.flatten() if n_rows > 1 or n_cols > 1 else [axes]

        for idx, col in enumerate(numeric_cols):
            if idx >= len(axes):
                break

            ax = axes[idx]

            # Гистограмма с KDE
            sns.histplot(data[col], kde=True, ax=ax, bins=30, color='skyblue')
            ax.set_title(f'{col}\n(n={len(data[col].dropna())})', fontsize=11)
            ax.set_xlabel('')
            ax.set_ylabel('Частота')

            # Добавляем статистику в текстовом виде
            stats_text = f"mean: {data[col].mean():.2f}\n"
            stats_text += f"std: {data[col].std():.2f}\n"
            stats_text += f"min: {data[col].min():.2f}\n"
            stats_text += f"max: {data[col].max():.2f}"

            ax.text(0.05, 0.95, stats_text,
                   transform=ax.transAxes,
                   verticalalignment='top',
                   fontsize=9,
                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

        # Скрываем лишние оси
        for idx in range(len(numeric_cols), len(axes)):
            axes[idx].set_visible(False)

        plt.suptitle('Распределение числовых признаков (гистограммы)', fontsize=16, y=1.02)
        plt.tight_layout()
        plt.show()

    # 2. Boxplot для числовых признаков
    if numeric_cols:
        n_numeric = len(numeric_cols)
        n_cols = 4  # Фиксируем 4 графика в ряду
        n_rows = int(np.ceil(n_numeric / n_cols))

        fig, axes = plt.subplots(n_rows, n_cols, figsize=(figsize[0], n_rows * 4))
        axes = axes.flatten() if n_rows > 1 or n_cols > 1 else [axes]

        for idx, col in enumerate(numeric_cols):
            if idx >= len(axes):
                break

            ax = axes[idx]

            # Boxplot
            sns.boxplot(y=data[col], ax=ax, color='lightgreen')
            ax.set_title(col, fontsize=11)
            ax.set_ylabel('Значения')

            # Добавляем информацию о выбросах
            q1 = data[col].quantile(0.25)
            q3 = data[col].quantile(0.75)
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)][col]

            ax.text(0.05, 0.95, f'Выбросы: {len(outliers)}\n({len(outliers)/len(data)*100:.1f}%)',
                   transform=ax.transAxes,
                   verticalalignment='top',
                   fontsize=9,
                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

        # Скрываем лишние оси
        for idx in range(len(numeric_cols), len(axes)):
            axes[idx].set_visible(False)

        plt.suptitle('Boxplot числовых признаков', fontsize=16, y=1.02)
        plt.tight_layout()
        plt.show()

visualize_dataset_attributes(data, target_col='class')

"""Напишите выводы по полученным графикам

6.3. Выполнить ***оценку баланса класса*** с помощью круговой диаграммы распределения результирующего атрибута.
"""

x = data['class'].value_counts()
plt.pie(x.values,
        labels = x.index,
        autopct='%1.1f%%')
plt.show()

"""Напишите выводы"""